{
  "hash": "4e51f3f8cd94c016448fa6523017407c",
  "result": {
    "markdown": "---\ntitle: 1. Measurement, Variance and Inferential Statistics\nsubtitle: \"Richard Philpot, Mark Hurlstone\"\norder: 2\n---\n\n\n# Lecture\n\nWatch Part 1 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=1981602)\n\nWatch Part 2 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=1981612)\n\nWatch Part 3 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=1981614)\n\nWatch Part 4 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=1981618)\n\nWatch Part 5 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=1981621)\n\nDownload the lecture slides [here](data/Wk1/Lecture 1 - Student Slides.pdf), and [here](data/Wk1/Psyc214 - Lecture 1 Week 1 - Student Slides [large].pdf) for a larger version.\n\n# Lab\n\nWelcome back to Lancaster University and congratulations on your progression to Year 2!\n\n\nThis will be the first lab session for Psyc214 - Statistics for Psychologists. In these lab sessions you will work from sheets (like this one) which detail activities and provide hands on experience of working and problem solving in R. At times these sheets will offer step-by-step instructions of how to wrangle data and to run a relevant command or analysis. At other times, and to reinforce learning, you will be asked to 'fill in the gaps' yourselves or to rewrite the code to solve a new problem. Myself (Richard Philpot), Mark Hurlstone and an apt team of GTAs will be on hand to help you through this journey - so please do not panic - you're never alone. In Psyc214, we also encourage peer engagment and joined problem solving - so please do not hesitate to ask for help from another on your table or to work together in small groups. Right, that enough for now, so let's get started!ðŸ’ª\n  \n******\n## 1 - General Introduction\n\n| *\"Once more unto the breach, dear friends, once more\"* | King Henry V, by William Shakespeare.\n\n![Fifty shades of rust](https://images.pexels.com/photos/1301413/pexels-photo-1301413.jpeg?cs=srgb&dl=pexels-magda-ehlers-1301413.jpg&fm=jpg)\n\nThe formation of rust can occur quickly and within minutes or slowly, over many years. It all depends on the material that is rusting, it's lack of use and the environment!\n\nIn this analogy, let's consider our 'R brains' as the material vulnerable to rusting. With individual differences, some of us may remember more of last year's statistic course than others - and that's completely normal.\n\nWhen considering repeated use and our environments, it is also unlikely that many of us have interacted with R and statistics over the intervening summer months. Quite sensibly we've enjoyed a non-academic environment - holidays, summer jobs, commitments to family and friends, these are all important things that have rightly taken priority!\n\n\nIt therefore an entirely natural process for folks to feel rusty and hesitant when re-engaging with R and statistics. As such, in this first session, let's get re-accustomed with our old friend 'R'.\n\n\n  \n******\n### 1.1 Access to R Studio\n\nYou will recall from last year that R Studio is a free, open-source data science engine that works as a giant calculator on steroids. Beyond number crunching, R studio allows you to organise your data, construct beautiful tables and graphs, as well as document your code and findings for others to inspect.\n\n![Vintage computational power and R Studio](https://images.unsplash.com/photo-1607370883617-9720ac853cc4?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1650&q=80)\n\n---\ntitle: \"Statistics for Psychologists\"\npage-layout: article\n---\n\nTo log in to the R server, first make sure that you have the VPN switched on, or you will need to be connected to the university network (Eduroam). To set up the VPN, follow ISS' [instructions here](https://portal.lancaster.ac.uk/ask/digital/services/university-it-network/vpn/) or connecting to Eduroam [here](https://portal.lancaster.ac.uk/ask/digital/services/university-it-network/wi-fi/).\n\nWhen you are connected, navigate to [https://psy-rstudio.lancaster.ac.uk](https://psy-rstudio.lancaster.ac.uk), where you will be shown a login screen that looks like the below. Click the option that says \"Sign in with SAML\".\n\n![](/Includes/1LoginSAML.png) <!-- says no image but it's all about the include setup -->\n\nThis will take you through to the University login screen, where you should enter your username (e.g. ivorym) and then your university password. This will then redirect you to the R server where you can start using RStudio!\n\n![](/Includes/2LoginUser.png)\n\n![](/Includes/3LoginPass.png)\n\n::: {.callout-note}\nIf you have already logged in through the university login already, perhaps to get to the portal, then you may not see the username/password screen. When you click login, you will be redirected straight to RStudio. This is because the server shares the login information securely across the university.\n:::\n\n\n\n******\n### 1.2 Creating a folder for today's session\n\nOnce you are logged into the server, create a folder for todayâ€™s session. This will be where we will house today's data and script. This will allow you to save you store your work and return at a later date (for example, around exam time - wink wink)\n\nNavigate to the bottom right panel (see figure below) and click Home. Next, under the Files option select the New Folder option. Name the new folder psyc214_lab_1. Please ensure that you spell this correctly otherwise when you set the directory using the command given below it will return an error.\n\n![Creating a folder on your server](images/Lab1_folder.png)\n\n\n******\n### 1.3 Uploading today's data file and creating a script\n\nNow that you have created a folder for todayâ€™s session, itâ€™s time to add the Week 1 data file. You can download the file from [here](data/Wk1/week1_robo_lab.csv). \n\nNext, in the RStudio Server open your new psyc214_lab_1 folder. When in the new folder, select the Upload tab (see figure below). This will present a box that will ask where the data is that you want to upload. Click on Browse, find the `week1_robo_lab.csv` file on your desktop and click OK.\n\n\n![Uploading today's data](images/Lab1_upload_files.png)\n\nSo we can save this session on the server, click File on the top ribbon and select New project. Next, select existing directory and name the working directory `~/psyc213_lab_1` before selecting create project.\n\nFinally, open a script for executing todayâ€™s coding exercises. Navigate to the top left pane of RStudio, select File -> New File -> R Script. Working from a script will make it easier to edit your code and you will be able to save your work for a later date.\n\n![Creating a script](images/Lab1_script.png)\n\n**Be sure to save the script using the File -> Save As....**\n\n******\n### 1.4 Setting the working directory and opening the data file\n\nA working directory is the default location or folder on your computer/server by which R will read/save any files. It can be set with the following R code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  setwd(\"/PSYC214\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsetwd(\"~/psyc214_lab_1\")\n```\n:::\n\n\nNow you've downloaded the data and set the working directory it's time to open the data file in R studio. To do this, please type the following code:\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nlab1_data <- read.csv(\"week1_robo_lab.csv\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n  \n  where 'lab1_data' is the name we've assigned that R will recognise when it calls up our data, 'read.csv' is the R command to pull up the data and 'week1_robo_lab.csv' is the name of the original data file you downloaded and stored.\n\n*Note. During the rest of this session, you will not need to refer to the original downloaded .csv data file. R has all the information stored under the â€˜lab1_dataâ€™ variable. Further note, you could have called â€˜lab1_dataâ€™ by pretty much any name you likeâ€¦ â€˜df1â€™, â€˜robo_1', â€˜I.love.stats.comâ€™, etc. - the name is somewhat arbitrary. For the purpose of this lab session and for ease of read, â€˜lab1_dataâ€™, is perhaps more suitable.*\n  \n******\n### 1.5 loading the relevant library  \n  \nFinally, letâ€™s load the relevant libraries that we will be using in todayâ€™s session:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rstatix)\nlibrary(ggpubr)\n```\n:::\n\n\n------ \n## 2 - Today's lab activities \n\nNow that you have loaded the dataset, let's have a play.\n\n\n### 2.1 Some background information about the dataset\n\n![Introducing the robo-lab study](https://images.pexels.com/photos/8386434/pexels-photo-8386434.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260)\n\nIn this lab session, we will examine the fictitious 'robo_lab' dataset.\nHere, a team of researchers wanted to know whether LU statistics students would respond well to a new, ambitious initiative to deploy a team of synthetic robots as lab assistants.\n  \n******\n### 2.2 Study manipulation\n\nThe research team developed two robot prototypes and wanted to test which prototype would be optimal for classroom teaching. \nIn a controlled experiment, the researchers randomly assigned groups of students either Robot A(lpha) or Robot B(eta). Note this is one factor design (Robot assignment) made of two levels (Robot A or Robot B).\n\nThose individuals assigned Robot A(lpha) were denoted as belonging to 'Group A'.\n\\\nThose individuals assigned Robot B(eta) were denoted as belonging to 'Group B'.\n\\\nNote. The groups are mutually exclusively - i.e., a participant was assigned to either Group A/Robot A or Group B/Robot B, not both.\n\n![**Robot A(lpha)**](images/Wk1/RobotA.png)\n\n![**Robot B(eta)**](https://images.pexels.com/photos/2599244/pexels-photo-2599244.jpeg?auto=compress&cs=tinysrgb&h=750&w=1260)\n  \n******\n### 2.3 Dependent (a.k.a. Outcome) variables\n\nNext, the researchers required some outcome measures to evaluate whether indeed the students had responded more positively toward one robot prototype over another.\n\nThe research team settled on two dependent variables (or outcome measures). These measured student stats competence (something important!) and attitudes towards teaching support (something also very important!).\n\nDV1: Student stats competence was measured by a Psyc214 test score; ranging between 40-100.\n\nDV2: Student attitudes towards the robot lab assistant was assessed with a likert scale response between 1-7; with 1 = 'strongly dislike' and 7 = 'strongly like'.\n  \n******\n### 2.4 Predictions of the research team\n\nThe research team had their own expectations for which robot would be best received by students.\nSpecifically, they predicted that:\n\n- Individuals assigned Robot B(eta) would score significantly higher in their Psyc214 tests (Hypothesis 1)\n\n- Robot B(eta) would be significantly more liked than Robot(A)lpha (Hypothesis 2)\n\nThe researchers expected that this difference would be explained by Robot B(eta)'s closer resemblance to other human beings. Indeed, prior to the study, independent raters had reliably agreed that Robot B(eta) resembled a human being significantly more than Robot A(lpha).\n  \n******\n### 2.5 Refamiliarising with some basic features\nNow that you have opened the dataset and are aware of what the different variables for this study are, it's time to explore.\n\nIn this first refresher session, we will be refamiliarising ourselves with some of the key functions and features learned in last year stats classes. \n\nEarlier, we loaded the package `dplyr`, which is readily accessible from the `tidyverse` collection. This package allows us to use some nifty functions such as:\n\n- pipes `%>%`  \n- `arrange()`\n- `summary()`\n- `sd()`\n- IQR, etc.\n  \n******\n### 2.6 Examining and ordering data\n\nNow that we have our pieces in play, let's take a look at the data.\n\nWe first want to get a brief overview of what the data set looks like. \nTo do this, we use the use the `head()` command, which displays the first rows present in the data frame.\n\nTo view these first rows, please apply the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  head(lab1_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  ID Group Likeability Score\n1  1     A           3    55\n2  2     A           2    72\n3  3     A           2    45\n4  4     A           3    50\n5  5     A           2    45\n6  6     A           5    63\n```\n:::\n:::\n\n\nThis shows us the first 6 rows. Note, while the default is six, you can also specify the number of rows as follows - please try it out.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  head(lab1_data, n=12)\n```\n:::\n\n\nGreat. We can now see the first 12 rows of data. \nOne thing that is noticeable, however, is that the data are ordered by participant 'ID'. Say we want to get an overview of our data where we can see data ordered by the from lowest Psyc214 test score to highest. We can arrange data this way using the `arrange()` command, were we include 'Score' as the variable of interest. Please try the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  lab1_data %>% arrange(Score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     ID Group Likeability Score\n1    33     A           2    40\n2    60     A           1    40\n3   165     B           5    40\n4    81     A           3    41\n5    46     A           3    42\n6    52     A           2    42\n7    18     A           4    43\n8    44     A           3    43\n9    95     A           3    43\n10   50     A           3    44\n11   53     A           1    44\n12   87     A           3    44\n13    3     A           2    45\n14    5     A           2    45\n15    7     A           4    45\n16   26     A           1    45\n17   28     A           4    46\n18  126     B           5    46\n19   39     A           4    47\n20   61     A           1    47\n21   66     A           4    47\n22   85     A           3    47\n23  133     B           3    47\n24   51     A           3    48\n25   57     A           2    48\n26   86     A           3    48\n27   96     A           4    48\n28   12     A           6    49\n29   40     A           3    49\n30  144     B           4    49\n31  162     B           4    49\n32  167     B           5    49\n33  172     B           4    49\n34  192     B           5    49\n35    4     A           3    50\n36   43     A           2    50\n37   79     A           2    50\n38  173     B           3    50\n39  191     B           5    50\n40   71     A           7    51\n41   91     A           4    51\n42  140     B           5    51\n43  147     B           6    51\n44  166     B           5    51\n45  170     B           6    51\n46  200     B           5    51\n47   24     A           3    52\n48  121     B           6    52\n49  176     B           4    52\n50   17     A           5    53\n51   38     A           4    53\n52   42     A           2    53\n53   62     A           2    53\n54   97     A           4    53\n55  105     B           4    53\n56  110     B           6    53\n57  131     B           7    53\n58   13     A           1    54\n59   64     A           3    54\n60   74     A           2    54\n61  101     B           4    54\n62  194     B           4    54\n63    1     A           3    55\n64   31     A           3    55\n65   37     A           1    55\n66   49     A           2    55\n67   70     A           3    55\n68  111     B           5    55\n69  128     B           6    55\n70  155     B           4    55\n71  163     B           3    55\n72  174     B           4    55\n73  177     B           5    55\n74   72     A           1    56\n75   82     A           3    56\n76  104     B           3    56\n77  136     B           6    56\n78  151     B           3    56\n79  184     B           5    56\n80   14     A           3    57\n81   15     A           2    57\n82   20     A           3    57\n83   45     A           3    57\n84  106     B           5    57\n85  135     B           4    57\n86  139     B           4    57\n87  149     B           4    57\n88  153     B           4    57\n89  168     B           5    57\n90   23     A           3    58\n91   35     A           4    58\n92   36     A           3    58\n93   48     A           2    58\n94   76     A           4    58\n95  109     B           4    58\n96  113     B           7    58\n97  180     B           5    58\n98    9     A           4    59\n99   54     A           2    59\n100  55     A           3    59\n101 102     B           3    59\n102 118     B           3    59\n103 125     B           5    59\n104 150     B           4    59\n105 186     B           5    59\n106 190     B           6    59\n107  16     A           3    60\n108  69     A           2    60\n109  83     A           3    60\n110  90     A           2    60\n111 115     B           5    60\n112 120     B           4    60\n113 143     B           4    60\n114 185     B           4    60\n115 187     B           5    60\n116 193     B           4    60\n117  22     A           2    61\n118  59     A           3    61\n119  92     A           4    61\n120 161     B           5    61\n121  21     A           3    62\n122  27     A           2    62\n123  32     A           2    62\n124  75     A           3    62\n125  77     A           3    62\n126  89     A           4    62\n127 148     B           5    62\n128   6     A           5    63\n129  80     A           4    63\n130  99     A           3    63\n131 100     A           4    63\n132 158     B           7    63\n133  19     A           2    64\n134  25     A           4    64\n135  41     A           3    64\n136  56     A           2    64\n137  68     A           3    64\n138  98     A           4    64\n139 122     B           5    64\n140 152     B           4    64\n141 181     B           4    64\n142 188     B           4    64\n143  58     A           3    65\n144  67     A           0    65\n145  78     A           3    65\n146  84     A           4    65\n147  88     A           4    65\n148  93     A           4    66\n149 119     B           5    66\n150 137     B           5    66\n151 196     B           5    66\n152  29     A           3    67\n153  34     A           4    67\n154  63     A           3    67\n155 130     B           2    67\n156 171     B           3    67\n157 199     B           6    67\n158  73     A           3    68\n159 103     B           3    68\n160 114     B           6    68\n161 123     B           5    68\n162 195     B           5    68\n163   8     A           4    69\n164 116     B           5    69\n165 129     B           3    69\n166 164     B           4    69\n167 198     B           3    69\n168  47     A           3    70\n169  65     A           1    70\n170 112     B           5    70\n171 141     B           5    70\n172 154     B           3    70\n173 157     B           4    70\n174 132     B           6    71\n175 146     B           4    71\n176 179     B           2    71\n177 182     B           5    71\n178   2     A           2    72\n179  11     A           3    72\n180 169     B           4    72\n181 197     B           5    72\n182  94     A           3    73\n183 107     B           3    73\n184 127     B           5    74\n185 159     B           4    75\n186 142     B           5    76\n187  30     A           6    78\n188 160     B           6    78\n189 117     B           5    80\n190 189     B           4    80\n191 108     B           3    81\n192 124     B           4    81\n193 138     B           5    81\n194 145     B           4    82\n195  10     A           1    83\n196 156     B           4    83\n197 183     B           4    85\n198 134     B           5    86\n199 175     B           5    88\n200 178     B           5    88\n```\n:::\n:::\n\n\nYou will note that the command outputs 100+ data rows showing the values of over 100 of our participants.\n\nThis can be quite a whooper!\n\nIf we want to make this output more manageable we could always add an additional `>%>` pipe command which combines both arrange and head.\n\nFor example the code below, combining `arrange()` and `head()` allows us order the data based on lowest score and then to display *only* the top 10 results. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n  lab1_data %>% arrange(Score) %>% head(n=10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    ID Group Likeability Score\n1   33     A           2    40\n2   60     A           1    40\n3  165     B           5    40\n4   81     A           3    41\n5   46     A           3    42\n6   52     A           2    42\n7   18     A           4    43\n8   44     A           3    43\n9   95     A           3    43\n10  50     A           3    44\n```\n:::\n:::\n\n\nPhew. This is more manageable.\n\nThis table provides some interesting information. We can see that the lowest scores were 40, which was the bottom cutoff point of our measurement scale. \n\nA quick eyeballing of the data rows suggests the lowest 10 test scores predominately have participants who were assigned to Group A(lpha). In fact, 9 out of 10 of the lowest scores belonged to individuals from Group A.\n\nIt would also be prudent to check the top 10 highest scores and to get a feel for what the top marks were like. We can again order our data using the `arrange()` function. This time however, we add the term `arrange(desc())` to show that we are asking R for descending ordering.\n\nPlease try the following command to examine the top scorers\n\n::: {.cell}\n\n```{.r .cell-code}\n  lab1_data %>% arrange(desc(Score))\n```\n:::\n\n\nYou will note in your own output, that the scores are once again showing over 100 values!\n\nTo make this more manageable, please try writing your own code combining the `arrange(desc())` command, a pipe `%>%` and the `head(n = x)` command. If stuck, refer to the command we used higher up.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#ANSWER CODE\nlab1_data %>% arrange(desc(Score)) %>% head(n=10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    ID Group Likeability Score\n1  175     B           5    88\n2  178     B           5    88\n3  134     B           5    86\n4  183     B           4    85\n5   10     A           1    83\n6  156     B           4    83\n7  145     B           4    82\n8  108     B           3    81\n9  124     B           4    81\n10 138     B           5    81\n```\n:::\n:::\n\n\nYou now should have an output of descending scores which are more manageable.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n    ID Group Likeability Score\n1  175     B           5    88\n2  178     B           5    88\n3  134     B           5    86\n4  183     B           4    85\n5   10     A           1    83\n6  156     B           4    83\n7  145     B           4    82\n8  108     B           3    81\n9  124     B           4    81\n10 138     B           5    81\n```\n:::\n:::\n\n\nTry eyeballing these scores and group IDs to see whether the higher scores tend to be associated with one group over another. Any thoughts?\n  \n******\n### 2.7 Assessing the descriptives\n\nAs of yet, we have not examined the basic descriptive statistics of our data, so let's take a look now.\n\nWe can compute the minimum and maximum values, 1st and 3rd quartiles, median and mean all at once using the `summary()` command:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lab1_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       ID            Group            Likeability        Score      \n Min.   :  1.00   Length:200         Min.   :0.000   Min.   :40.00  \n 1st Qu.: 50.75   Class :character   1st Qu.:3.000   1st Qu.:53.00  \n Median :100.50   Mode  :character   Median :4.000   Median :59.00  \n Mean   :100.50                      Mean   :3.725   Mean   :59.69  \n 3rd Qu.:150.25                      3rd Qu.:5.000   3rd Qu.:66.00  \n Max.   :200.00                      Max.   :7.000   Max.   :88.00  \n```\n:::\n:::\n\n\nThere are still a number of descriptives which may be interesting, but that the `summary()` function does not provide, however.\n\nFor example, we may be interested in ... (remember from last lecture ;) ...:\n\n- the range of our data points (i.e., the difference between the lowest and highest values)\n- the interquartile range of data (i.e., the difference between the first and third quartiles) \n- the standard deviation (i.e.,  the dispersion of a dataset relative to its mean, that being the square root of the variance)\n\nThese can all be calculated relatively easily with the following commands:\n\n- the range of our data points: `range()`\n- the interquartile range: `IQR()`\n- the standard deviation: `sd()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrange(lab1_data$Score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 40 88\n```\n:::\n\n```{.r .cell-code}\nIQR(lab1_data$Score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 13\n```\n:::\n\n```{.r .cell-code}\nsd(lab1_data$Score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10.29689\n```\n:::\n:::\n\n\nNote that this only provides the information for the 'Scores' dependent variable - I.e., DV1.\n\nWe do not know what the respective values are for the 'Likeability' dependent variable (DV2).\n\nIf we want to examine multiple variables simultaneously, we can use the `sapply()` function, which can take multiple lists/vector/data frames as inputs within a single command. Nifty.\n\nHere, we need to specify which columns we would like to assess. In our data the 'Scores' dependent variable (DV1) and 'Likeability' dependent variable (DV2) are columns 4 and 3 of the datasheet, respectively.\n\nLet's try in with the range.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsapply(lab1_data[, 4:3], range)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Score Likeability\n[1,]    40           0\n[2,]    88           7\n```\n:::\n:::\n\n\nHere we see that the range in Psyc214 test scores (i.e., the min and max scores in the cohort of all participants) ranged between 40 and 88.\n\nAlso, the min and max ratings for the likeability scores were between 0 and 7, respectively.\n\nNow, please try to apply the code above yourself, but change 'range' with the standard deviation 'sd' function to get the standard deviation for both the score and likeability variables simultaneously.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#ANSWER CODE\nsapply(lab1_data[, 4:3], sd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      Score Likeability \n  10.296888    1.344774 \n```\n:::\n:::\n\n\nIf done correctly, you should received the following output:\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n      Score Likeability \n  10.296888    1.344774 \n```\n:::\n:::\n\n\n  \n******\n### 2.8 Descriptives by group condition\n\nNow that we have some information regarding the overall data, we can rejoice.\n\nWell only briefly...\n\nAlthough this information is useful, it gives information regarding all data points and does not generate these values based on the two assigned independent groups - i.e., the two levels (Group Robot A, Group Robot B) of our single factor (Robot Assignment).\n\nAlthough there are work arounds for this, simpler functions are available in the rstatix() package (previously loaded).\n\nUsing the package's `group_by()` command and pipes `%>%` we can ask R to separate our data based on the group assigned. Note, here the name of the grouping variable for our dataset is 'Group'.\n\nLet's ask for the mean for our two groups with the following command. \nFirst we tell R we are using the lab1_data. Then we say within this data set we want to separate the data by the 'Group' variable. Finally we ask for summary stats for the DV1 the Score. We will ask only for the mean.\n  \n\n::: {.cell}\n\n```{.r .cell-code}\n  lab1_data %>%\n  group_by(Group) %>%\n  get_summary_stats(Score, type = \"mean\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 Ã— 4\n  Group variable     n  mean\n  <chr> <fct>    <dbl> <dbl>\n1 A     Score      100  56.6\n2 B     Score      100  62.8\n```\n:::\n:::\n\n\nGreat. Now let's do the same again, but this time we will ask for summary statistics for both the Score (DV1) and Likeability (DV2) variables. Furthermore, let's also ask for the sd, min, max and iqr.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  lab1_data %>%\n  group_by(Group) %>%\n  get_summary_stats(Score, Likeability, show = c(\"mean\", \"sd\", \"min\", \"max\", \"iqr\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 Ã— 8\n  Group variable        n  mean    sd   min   max   iqr\n  <chr> <fct>       <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 A     Score         100 56.6   9.05    40    83    14\n2 A     Likeability   100  2.94  1.15     0     7     2\n3 B     Score         100 62.8  10.6     40    88    15\n4 B     Likeability   100  4.51  1.03     2     7     1\n```\n:::\n:::\n\n\nOk, perfect. This now tells us a lot of information. For example, we can see that the mean test scores for Group A and B are 56.6 and 62.8 respectively. On reflection, and considering the importance of getting a nice score, these means do seem quite different from one another. \n  \n******\n\n## 3. And more\n\n### 3.1 Visualising data\n\nAs a next step, let's plot the data and see the distribution of data points in visual form. To do this, we've already loaded the excellent data visualization package `ggpubr`.\n\nTo plot the data we use the `ggboxplot()` command.\nFirst we are required to say what dataset we'll be using, which is again 'lab1_data'. Next we type 'main=' to specify the title for the plot. Let's call the plot \"Box plot of test scores by robot condition\". We then need to specify what data we would like to use for each axis. For the x-axis we would like to plot the different groups, so let's add x = \"Group\". Our y-axis will be the \"Score\". We can colour the groups also and add shapes to data points. Finally, let's give the x-axis and y-axis each a descriptive label. \"Robot group condition\" and \"Psyc214 test score\" seem appropriate here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Box plot of test scores by Robot Condition\nggboxplot(lab1_data,main=\"Box plot of test scores by robot condition\", \n               x = \"Group\", y = \"Score\", #variables for axes\n                color = \"Group\", palette =c(\"#999999\", \"#333333\"), #colour of data\n                add = \"jitter\", shape = \"Group\", # shape of data\n               xlab=\"Robot group condition\", ylab=\"Psyc214 test score\") #labels for axes\n```\n\n::: {.cell-output-display}\n![](Week1_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nObserving the spread of data points for Group A and B, respectively, we can see trends in which Group B tends to have more data points clustered higher on the test score axis than Group A. Group A has more data points clustered lower on the test score axis than Group B and these distributions are reflected by the boxplots. Again it seems we have a signficant difference, but we will need a statistical test to be certain.\n  \n******\n### 3.2 Independent 2-group T-test\n\nTo get to the bottom of this we need to perform an independent 2-group t-test. This inferential statistical test is appropriate when you want to examine whether there are any statistically significant differences between the means of two unrelated groups. This can be run using the `t_test()` function, where 'Score' is our y (dependent variable) and 'Group' is our predictive factor x (independent variable).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# independent 2-group t-test\n  #t_test(Score ~ Group) # where y is numeric Score and x is a binary factor \n# Compute t-test\n t.test(formula = Score ~ Group, pool.sd = FALSE, var.equal = TRUE, data = lab1_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  Score by Group\nt = -4.4152, df = 198, p-value = 1.658e-05\nalternative hypothesis: true difference in means between group A and group B is not equal to 0\n95 percent confidence interval:\n -8.896848 -3.403152\nsample estimates:\nmean in group A mean in group B \n          56.61           62.76 \n```\n:::\n:::\n\n\nThe output provides the t-value and itâ€™s 95% confidence interval - i.e., we can be 95% certain that the true value of t falls within the the lower and upper confidence intervals. We also get the means of our groups, the degrees of freedom for our t-test and the p-value. \nThis p-value is significantly lower than 0.05 meaning that we reject the null hypothesis - i.e., we accept that the true difference is not roughly equal to zero. As such, there is a statistical difference in Psyc214 assessment scores between the two groups. What we are yet to discover is whether this represents a small, moderate or large effect.\n\nTo calculate the effect size, where 0.2 = small effect, 0.5 = moderate effect, 0.8 = large effect (Cohen, 1988), we use the 'cohens_d()' function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Cohen's d effect size calculation\ncohens_d(Score ~ Group,  # Formula\n       data = lab1_data) # Dataframe containing the variables\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 Ã— 7\n  .y.   group1 group2 effsize    n1    n2 magnitude\n* <chr> <chr>  <chr>    <dbl> <int> <int> <ord>    \n1 Score A      B       -0.624   100   100 moderate \n```\n:::\n:::\n\n\nThis output shows us that we have a moderate negative effect of -0.62 ; note. it is negative because of the order of our factors - i.e., Group A (which is presented first in our equation) has a lower set of scores than Group B. As you typically report the effect size as a value between 0-1 we need to treat the result as an absolute value, meaning we ignore the minus symbol when reporting our results.\n  \n******\n### 3.3 Reporting the results of the independent 2-group T-test in APA format\n\nAll results should be written up in accordance with the American Psychological Association's (APA) guidance. This ensures that your results are easy to interpret and that all the relevant information is present for those wishing to review/replicate your work.\n\nThe current results can be reported as following:\n\"An independent 2-group T-test was carried out to examine whether there were statistical differences in the Psyc214 assessment scores between those students assigned Robot A(lpha) and those assigned Robot B(eta). This test was found to be statistically significant, *t*(198)= -4.42, 95% CI [-8.90, -3.40], *p* < .001, *d* = 0.62. This effect size represents a moderate effect (Cohen, 1988). These results indicate that individuals assigned Robot A(lpha) (*M* = 56.61, *SD* = 9.05) typically received lower Psyc214 assessment scores than those individuals assigned Robot B(eta) (*M* = 62.76, *SD* = 10.60)\"\n  \n******\n## 4. Further tasks\n\n1. repeat the steps in '2.8 Descriptives by group condition', this time examining the summary statistics for our second dependent variable - 'Likeability'.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  #ANSWER CODE\n  lab1_data %>%\n  group_by(Group) %>%\n  get_summary_stats(Likeability, type = \"mean\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 Ã— 4\n  Group variable        n  mean\n  <chr> <fct>       <dbl> <dbl>\n1 A     Likeability   100  2.94\n2 B     Likeability   100  4.51\n```\n:::\n:::\n\n\n2. repeat the steps in '3.1 Visualising data', this time creating box plots for our second dependent variable - 'Likeability'. Rename the title and axes to something more suitable and perhaps even change the colour of data points. Describe the trends in data to a classmate or your inner self.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#ANSWER CODE\n  # Box plot of likeability scores by Robot Condition\nggboxplot(lab1_data,main=\"Box plot of test scores by robot condition\", \n               x = \"Group\", y = \"Likeability\", #variables for axes\n                color = \"Group\", palette =c(\"#999999\", \"#333333\"), #colour of data\n                add = \"jitter\", shape = \"Group\", # shape of data\n               xlab=\"Robot group condition\", ylab=\"Likeability scores\") #labels for axes\n```\n\n::: {.cell-output-display}\n![](Week1_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n3. compute an independent t-test (steps 3.2) to examine whether there are any statistical differences between the means of our two groups in their Likeability ratings. Write up the results in APA style.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#ANSWER CODE\n# independent 2-group t-test\n  #t_test(Score ~ Group) # where y is numeric Score and x is a binary factor \n# Compute t-test\n t.test(formula = Likeability ~ Group, pool.sd = FALSE, var.equal = TRUE, data = lab1_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  Likeability by Group\nt = -10.155, df = 198, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group A and group B is not equal to 0\n95 percent confidence interval:\n -1.874879 -1.265121\nsample estimates:\nmean in group A mean in group B \n           2.94            4.51 \n```\n:::\n\n```{.r .cell-code}\n  # Cohen's d effect size calculation\ncohens_d(Likeability ~ Group,  # Formula\n       data = lab1_data) # Dataframe containing the variables\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 Ã— 7\n  .y.         group1 group2 effsize    n1    n2 magnitude\n* <chr>       <chr>  <chr>    <dbl> <int> <int> <ord>    \n1 Likeability A      B        -1.44   100   100 large    \n```\n:::\n:::\n\n\n4. before you finish, make sure you save a copy of the script that you have been working on by the end of the session. This provides you with the record - the digital trace - on what you have done. And it means you can come back and repeat any of the work you have performed.\n\nPlease end your session on the RStudio server, this logs you out of the server and stops any ongoing activities and tasks you have set up, maybe in the background.\n\n![Ending session on R Studio](https://tombeesley.github.io/PSYC121_2022-23/files/Week_1/power_button.png)\n\n5. ...\n\nNow breathe! You've rocked it!!!\n\n![Top work!](https://images.unsplash.com/photo-1536193533103-5bb31b6fb667?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1170&q=80)\n\n\n# Lab Feedback (voluntary)\n\nThis is a voluntary, super fast [survey](https://modules.lancaster.ac.uk/mod/url/view.php?id=1905311), just to gauge how you found the difficulty of the content and any additional feedback.",
    "supporting": [
      "Week1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}