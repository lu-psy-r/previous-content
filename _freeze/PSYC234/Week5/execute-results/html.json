{
  "hash": "8f3ad993a57317fbb1e7ff1ab497f4d4",
  "result": {
    "markdown": "---\ntitle: 5. Factor analysis & the binomial test\nsubtitle: Emma Mills and Amy Atkinson\norder: 6\n---\n\n\n\n\n# Introduction\n\nThis week is a crossover week between Amy and Emma. Factor Analysis\ncontent is needed for learning and **WBA5.** Questions will not be asked\nin the class test in week 20 on the Factor Analysis method. The Binomial\nTest content is needed for learning, **WBA5** and the **class test**.\n\nThe rest of this page is split into two parts, Factor Analysis and\nBinomial Test. They each have their own associated lecture and notes.\n\n# Factor Analysis\n\nWatch the Lecture on Factor Analysis\n[here](https://modules.lancaster.ac.uk/mod/url/view.php?id=1978201)\n\nFactor analysis is an analysis method that aims to take a large number\nof observed variables, and reduce these to a smaller set of distinct\nunderlying latent variables. In the example below, we have the observed\nvariables on the left. These are the things we can measure, or observe.\nOn the right, we see the latent variables (PA1, PA2, PA3, and PA4),\nthese are not directly measured by us (hence the term latent) and\nrepresent a reduction of variables. This is done through measuring how\nthe observed variables \"load\" onto the latent variables (the loadings\nare the numbers on the arrows, higher loadings indicate stronger links\nto that latent variable) -- they correlate more with each other than the\nother variables, which can indicate that they measure a similar\nunderlying variable.\n\nYou may have taken a personality test, or other questionnaire style test\nwhere a lot of the questions seemed to ask about similar things. In the\nbig five mini-IPIP scale, the two questions for extraversion are \"Am the\nlife of the party\" and \"Talk to a lot of different people at parties\".\nThe expectation is that if there is indeed an underlying variable behind\nthese two questions, then people's responses should be similar to both\nquestions (score 5 - strongly agree to one statement and you'd probably\nscore the other the same).\n\n![Factor Analysis](Images/Wk5/FA.png)\n\nMeasures of association help answer the question 'What is the\nrelationship between two variables?'\n\nCorrelation looks at pairs of **numerical** variables\n\n-   X & Y below predict Z\n-   X & Y are completely separate\n-   X & Y are completely independent of each other\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div id=\"htmlwidget-9f9f11e37b98279419c6\" style=\"width:100%;height:464px;\" class=\"grViz html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-9f9f11e37b98279419c6\">{\"x\":{\"diagram\":\"digraph flowchart {\\n  node [fontname = arial, shape = oval]\\n  tab1 [label = \\\"X\\\"]\\n  tab2 [label = \\\"Y\\\"]\\n  tab3 [label = \\\"Z\\\"]\\n\\n  tab1 -> tab3;\\n  tab2 -> tab3;\\n\\n  {rank=same; tab1, tab2}\\n\\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n-   X & Y below predict Z\n-   X & Y are completely separate\n-   X & Y are completely independent of each other\n\nX is showing a larger correlation with Z than Y here\n\nYou can draw the diagram like this to show how much information X shares\nwith Z and how much Y shares with Z\n\n![Correlation of variables](Images/Wk5/Correlation1.png)\n\nSometimes the relationship between X & Y is not so independent: + X & Y\nhere still predict Z + X & Y but now they are not completely separate +\nX & Y they share some information + They are correlated with each\nother + As well as being correlated with Z\n\n![Correlation of variables](Images/Wk5/Correlation2.png)\n\nWe can draw this this way too...\n\nThe overlap between X & Y is still independent of their overlap with Z\n\n![Correlation of variables](Images/Wk5/Correlation3.png)\n\nIn this example, the overlap between X & Y is now related to the overlap\nwith Z to a much greater degree...\n\n![Correlation of variables](Images/Wk5/Correlation4.png)\n\n## Multicollinearity\n\nWhen we have too much overlap between our predictor variables it can be\na problem. This is called **multicollinearity**.\n\nWhen you have many predictor variables you need to check that they are\nnot too highly correlated with each other. You do this by calling a\ncorrelation plot, where correlations \\> .80 may be problematic. If you\nhave lots of observations, you may be okay, but your model may have\nproblems\n\n### Mitigation\n\nChoose a smaller set of variables \n\n+ By theory Group together alike variables \n+ Principal component analysis Estimate underlying structures \n+ Factor analysis \n+ Underlying structures are also known as\n\"latent variables\"\n\n## Factor Analysis\n\nFinding underlying structure or latent variables + Latent variables\nshould have three or more observed variables loading onto them +\nCorrelations between those observed variables should be high + The\nobserved variables should load only onto one variable\n\nBefore beginning: \n\n+ Standardise your variables\n\nFactor analysis is quite jargon heavy:\n\n*Exploratory factor analysis* (EFA) and *Confirmatory factor analysis*\n(CFA)\n\nWhere there is overlap, where variables '*load*' onto factors:\n\nThe shared variance is called '*communality*'\n\nAnd the unshared variance is called *uniqueness*\n\n### Performance\n\n1.  A factor should have at least three variables that are loaded to a\n    sufficient level\n2.  Any one variable should have most of its loading on one factor 3.A\n    factor should have good internal consistency (a common (and maybe\n    overused) method is Cronbach's alpha) 4.Factors should make\n    theoretical sense\n\nSnapshot of an example output below:   \n\n+ The first column is the labels of the observed variables \n+ Columns 2 -- 5 are the latent variable loadings for each of those observed variables. \n+ The first three factors each have 3+  of the observed variables \n+ Length is problematic here\n\n![Example of variable loadings](Images/Wk5/Loading_example.png)\n\n### Preparation\n\n1.  Remove outcome variables, categorical variables, ordinal variables\n\n2.  Visualise the prepared dataset\n\n3.  Inspect correlations (guidelines exist!)\n\n4. Perform some EFA specific tests to determine if a factor analysis is\nfeasible + KMO + Bartlett's test of sphericity + Parallel analysis +\nScree test (visualization) + Packages in R support these\n\n![Example of variable loadings](Images/Wk5/ExamplePrep.png)\n\n5. If the indications are good -- then perform a factor analysis\n\nGuidelines exist for all of the following: \n\n1. Look for patterns inside\nthe factors \n\n2. Look for patterns between the factors \n\n3. Look for\ncommunalities \n\n4. Look for factor correlations \n\n5. Test for internal\nconsistency of the factors \n\n6. Draw! Report!\n\n## Practice\n\nYou will need to review the Birthweight example to be able to complete\nWBA5.\n\nYou can choose any of the three examples to explore the process of\nFactor Analysis.\n\nBirthweight script and data\n[here](data/Wk5/Factor%20Analysis%20Materials/Birthweight%20Factor%20Analysis.zip),\nand codebook\n[here](data/Wk5/Factor%20Analysis%20Materials/Birthweight_data_kg_description.pdf)\n\nQuestionnaire script and data\n[here](data/Wk5/Factor%20Analysis%20Materials/Questionnaire%20Factor%20Analysis.zip)\n\nSingle Word Reading script and data\n[here](data/Wk5/Factor%20Analysis%20Materials/Single%20Word%20Reading%20Factor%20Analysis.zip)\n\nOr, download all the materials\n[here](data/Wk5/Factor%20Analysis%20Materials.zip) - treat yourself!\n\n# Binomial Test\n\nWatch the Lecture on the Binomial test\n[here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=2049284)\n\n## Preamble\n\nLet's think back to the one-sample t-test\n\nRQ: You are a researcher interested in whether babies born in Germany\nweigh more than babies born in the UK.\n\nLet's assume the following are true: \n\n+ The NHS keeps good records of\nbirth weights in the UK, and that the average birth weight in the UK in\n2020 was 3350g. \n\n+ The health authorities in Germany do not keep good\nrecords of birth weights.\n\nYou could collect birth weights from a sample of babies born in Germany\nand compare this to the known average in the UK (3350g).\n\n\n\n\n| Participant | Weight (g) |\n|-------------|------------|\n| 1           | 3004       |\n| 2           | 3052       |\n| 3           | 3067       |\n| 4           | 4063       |\n| 5           | 2134       |\n| 6           | 2356       |\n| 7           | 4356       |\n| 8           | 3567       |\n| 9           | 3432       |\n| 10          | 3245       |\n| 11          | 1467       |\n| 12          | 2345       |\n| 13          | 4532       |\n| 14          | 4352       |\n| 15          | 2453       |\n| 16          | 2343       |\n| 17          | 3453       |\n| 18          | 3428       |\n| 19          | 2344       |\n| 20          | 4353       |\n| **Mean**    | 3167.30    |\n\n: Birthweights of babies born in Germany\n\nIs the mean of the sample significantly different from a known value? to\ntest this, we can use a one-sample t-test!\n\n## Another example\n\nWhat if we asked the question: Is the moon made of cheese?\n\nTwo answers: Yes, and No.\n\nDoes the proportion of participants answering the question correctly differ from the chance guessing rate?\n\n| Participant | Answer |\n|-------------|--------|\n| 1           | No     |\n| 2           | No     |\n| 3           | **Yes**|\n| 4           | No     |\n| 5           | No     |\n| 6           | No     |\n| 7           | No     |\n| 8           | No     |\n| 9           | No     |\n| 10          | No     |\n| 11          | No     |\n| 12          | No     |\n| 13          | No     |\n| 14          | No     |\n\n: Responses to the question \"Is the moon made of cheese\"?\n\nHow many participants answered the question correctly?\n+ Correct (“No”) = 13/14 = 0.93\n\nWhat is chance guessing rate?\n+ 2 possible answers (yes/no), so chance = 50%, expressed as a proportion, this is 0.5 \n\n::: {.callout-note}\nTo convert a percentage to a proportion, divide by 100 = 50/100 = 0.5\n:::\n\n### Why can't we use the one-sample t-test?\n\nOne sample t-test: Is the mean of the sample significantly different from a known value?\n\nIssue: we can’t calculate a mean value for the sample – we have a proportion who answered correctly\n\nSo, we can’t use a one-sample t-test... What can we use?!\n\n### The binomial test!\n\nThe binomial test compares a sample proportion to a known value\n\nDoes a sample proportion differ significantly from a known value?\n\nKnown value may be theoretical (e.g. based on chance) or known data about the world (e.g. 26% people die from this disease)\n\nOther examples:\n\nYou notice that a lot of the insects in your garden are ants. You work out that 564 out of 712 insects are ants. You hear on a TV show that on average, 64% of insects in UK gardens are ants. Is the proportion of insects that are ants in your garden larger than UK average?\n\n- Proportion of sample that are ants are: 564/712 = 0.79\n- Known value (expressed as a proportion)= 0.64\n\nYou develop a new vaccine for an illness and give this to 1,000 people - 32/1000 given the vaccine get the illness within a year. You know that approximately 10% of unvaccinated people (or 0.1 expressed as a proportion) get the illness every year. Is the proportion of vaccinated people getting the illness lower than the known value for unvaccinated people?\n\n- Proportion of sample that get the illness: 32/1000 = 0.03\n- Known value (expressed as a proportion)= 0.10\n\nDoes a sample proportion differ significantly from a known value?\n\n### Binomial Test assumptions\n\n1. The outcome is dichotomous: \u000bThere are only two possible outcomes\n\n2. The outcome can be specified as success or failure\u000b\u000b\n\n3. Each trial is independent\n\n4. The probability of ‘success’ remains the same on every trial\n\n### Carrying out the binomial test\n\nBelow is the code needed for running a binomial test. Pretty simple!\n`binom.test` is a function that is in the base R package, meaning that\nwe don't need to load in any additional libraries to use it.\n\nThe first number is the number of successes (thirteen said no), the second number is the total number of trials (we asked fourteen people), and the last number is the known value, here expressed as a proportion (here chance guessing rate)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Code to run the binomial test\n\nbinom.test(13, 14, 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tExact binomial test\n\ndata:  13 and 14\nnumber of successes = 13, number of trials = 14, p-value = 0.001831\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.6613155 0.9981932\nsample estimates:\nprobability of success \n             0.9285714 \n```\n:::\n:::\n\n\nAnd here is an annotated version of the output\n\n![Annotated binom.test output](Images/Wk5/AnnotatedBinom.png)\n\n#### How do I interpret the p-value?\n\np ≤ .05 = The observed proportion differs significantly from the known value\n\np > .05 = The observed proportion does not differ significantly from the known value\n\n#### I have a significant effect... In what direction is the effect?\n\nIs the probability of success higher or lower than the known value?\n\nThe proportion of children answering the question correctly (.93) is significantly higher than the chance guessing rate (.50)\n\n#### What does the 95% confidence interval tell us?\n\nIf we repeat the sampling method many many times and compute a 95% confidence interval, 95% of the intervals would contain the true value in the population.\n\nRange that is likely to contain the true value\n\n![Confidence intervals](Images/Wk5/binom_CI.png)\n\n#### Reporting in APA format\n\nA binomial test was conducted to determine whether the proportion of participants answering the question correctly differed significantly from chance guessing rate. This revealed that that the proportion of participants answering the question correctly (93%; 95% confidence interval = 66-100%) was significantly higher than the chance guessing rate (50%; p = 0.002). \n\n## Post-lecture activities - Complete ideally before WBA\n\nThese can be downloaded [here](data/Wk5/binomial test - worksheet.zip) and contain a word document worksheet and the answers.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/htmlwidgets-1.5.4/htmlwidgets.js\"></script>\n<script src=\"../site_libs/viz-1.8.2/viz.js\"></script>\n<link href=\"../site_libs/DiagrammeR-styles-0.2/styles.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/grViz-binding-1.0.9/grViz.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}